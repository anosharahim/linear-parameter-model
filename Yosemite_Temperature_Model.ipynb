{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9d7b8b",
   "metadata": {},
   "source": [
    "# Yosemite Village yearly weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b553f35",
   "metadata": {},
   "source": [
    "## Part 0 - Data Preprocessing \n",
    "Temperature is cyclical, not only on a 24 hour basis but also on a yearly basis. Convert the dataset into a richer format whereby the day of the year is also captured. For example the time “20150212 1605”, can be converted into (43, 965) because the 12th of February is the 43rd day of the year, and 16:05 is the 965th minute of the day.\n",
    "\n",
    "This data covers 6 years, so split the data into a training set of the first 5 years, and a testing set of the 6th year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b152beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c76c9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2011, 2017) \n",
    "files = ['CRNS0101-05-%d-CA_Yosemite_Village_12_W.txt' % y for y in years]\n",
    "\n",
    "usecols = [1, 2, 8] #[UTC_time, UTC date, Temperature]\n",
    "tr = [np.loadtxt(f, usecols=usecols) for f in files]\n",
    "ts = np.loadtxt('CRNS0101-05-2016-CA_Yosemite_Village_12_W.txt', usecols=usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9051699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.000e+00,  0.000e+00, -1.900e+00],\n",
       "       [ 1.000e+01,  0.000e+00, -2.000e+00],\n",
       "       [ 1.500e+01,  0.000e+00, -2.100e+00],\n",
       "       ...,\n",
       "       [ 1.430e+03,  3.650e+02,  0.000e+00],\n",
       "       [ 1.435e+03,  3.650e+02, -1.000e-01],\n",
       "       [ 0.000e+00,  3.660e+02, -1.000e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST SET ## \n",
    "\n",
    "#convert dates from YYYYMMDD format to days since start of year\n",
    "ts_year = '20160101'\n",
    "ts_year_start = datetime.strptime(ts_year, '%Y%m%d')\n",
    "ts_date=pd.to_datetime(ts[:,0], format='%Y%m%d')\n",
    "ts_date.to_numpy()\n",
    "ts_days = ts_date - ts_year_start \n",
    "ts_days = ts_days / np.timedelta64(1, 'D')\n",
    "ts_days=ts_days.to_numpy()\n",
    "\n",
    "#convert time of day from HHMM to minutes since start of day \n",
    "hour_mins = np.divmod(ts[:,1],np.full((105408,), 100)) #two rows for hour and minutes each\n",
    "ts_minutes = (hour_mins[0]*60)+hour_mins[1] #add them together to get new array of time \n",
    "ts_minutes = ts_minutes.astype(int)\n",
    "\n",
    "#merge all columns\n",
    "test = np.column_stack((ts_minutes, ts_days,ts[:,2]))\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3455c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TRAIN SET ## \n",
    "\n",
    "tr_years = ['20110101','20120101','20130101','20140101','20150101']\n",
    "train_dates = [] #list for arrays of days for each year \n",
    "train_minutes = [] #list for array of day minutes for each year\n",
    "\n",
    "#convert date \n",
    "for i in range(len(tr_years)):\n",
    "\n",
    "    tr_year_start = datetime.strptime(tr_years[i], '%Y%m%d')\n",
    "    year_data = tr[i]\n",
    "    year_data=pd.to_datetime(year_data[:,0], format='%Y%m%d')\n",
    "    year_data.to_numpy()\n",
    "    year_data = year_data - tr_year_start \n",
    "    year_data = year_data / np.timedelta64(1, 'D')\n",
    "    year_data=year_data.to_numpy()\n",
    "    train_dates.append(year_data)\n",
    "    \n",
    "   \n",
    "#convert minutes\n",
    "for i in range(len(tr_years)):\n",
    "    \n",
    "    if tr[i][:,1].shape == (105120,):\n",
    "        #print(tr[i].shape)\n",
    "        h_n_m = np.divmod(tr[i][:,1],np.full((105120,), 100))\n",
    "        train_minutes.append((h_n_m[0]*60)+h_n_m[1])\n",
    "        h_n_m =0\n",
    "        \n",
    "    else: \n",
    "        h_n_m = np.divmod(tr[i][:,1],np.full((105408,), 100))\n",
    "        train_minutes.append((h_n_m[0]*60)+h_n_m[1])\n",
    "        h_n_m =0\n",
    "        \n",
    " \n",
    "#merge everything\n",
    "train_set = []\n",
    "for i in range(len(tr_years)):\n",
    "    train_set.append(np.column_stack((train_minutes[i], train_dates[i],tr[i][:,2])))\n",
    "    \n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d4e49",
   "metadata": {},
   "source": [
    "### Part 1 - Applying Radial Basis Functions \n",
    "Cover each input dimension with a list of radial basis functions. This turns the pair of inputs into a much richer representation, mapping (d,t) into (Φ₁(d), Φ₂(t)). Experiment with different numbers of radial basis functions and different widths of the radial basis function in different dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3fb04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2f82b68",
   "metadata": {},
   "source": [
    "### Part 2 - Build Linear Parameter Model \n",
    "Using this new representation, build a linear parameter model that captures both seasonal variations and daily variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12823742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94d7eb6e",
   "metadata": {},
   "source": [
    "## Part 3 - Visualization\n",
    "- Create two plots, one showing the time-of-day contribution, and one showing the time-of-year contribution.\n",
    "- (Optional) Make a 3D plot showing temperature as a function of (day, time). Make sure to label your axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c587769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea517c56",
   "metadata": {},
   "source": [
    "## Part 4 - Evaluation \n",
    "Using R², quantify how your model performs on the testing data if you:\n",
    "- Train with just the daily component of the model\n",
    "- Train with just the yearly component of the model\n",
    "- Train with the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64a8239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### PCW ### \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics.pairwise import rbf_kernel #get radial basis function kernel \n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "years = range(2011, 2017)\n",
    "files = ['CRNS0101-05-%d-CA_Yosemite_Village_12_W.txt' % y for y in years]\n",
    "\n",
    "\n",
    "usecols = [1, 2, 8] #[WBANNO (station number), UTC Date, Latitude]\n",
    "\n",
    "data = [np.loadtxt(f, usecols=usecols) for f in files] #load data with relevant columns\n",
    "#vstack() function is used to stack the sequence of input arrays vertically to make a single array. \n",
    "data = np.vstack(data) \n",
    "\n",
    "print(data)\n",
    "\n",
    "# Map data from HHmm to an integer\n",
    "data[:, 1] = np.floor_divide(data[:, 1], 100) * 60 + np.mod(data[:, 1], 100)\n",
    "valid = data[:, 2] > -1000 \n",
    "\n",
    "x_train = data[valid, 1].reshape(-1, 1) #utc time in minutes \n",
    "y_train = data[valid, 2] #latitude\n",
    "\n",
    "import random \n",
    "sigma = 0.1\n",
    "alp = 0.0001\n",
    "\n",
    "number_of_rows = x_train.shape[0]\n",
    "random_indices = np.random.choice(number_of_rows, size=1000, replace=True)\n",
    "w = np.random.sample(size =1000)\n",
    "\n",
    "x_train = x_train.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "x_train = x_train[random_indices, :]\n",
    "y_train = y_train[random_indices, :]\n",
    "\n",
    "print(max(x_train), max(y_train))\n",
    "print(min(x_train), min(y_train))\n",
    "print(len(x_train),len(y_train))\n",
    "\n",
    "rbf = rbf_kernel(y_train, x_train, gamma=1.0/sigma)\n",
    "regression = Ridge(alpha=alp, fit_intercept=False)\n",
    "regression.fit(rbf, y_train)\n",
    "\n",
    "print(\"Score on training data = \", regression.score(rbf, y_train))\n",
    "all_rbf = np.linspace(-3.0, 5.0, 1000).reshape(-1, 1)\n",
    "\n",
    "# New representation:\n",
    "expanded_rbf = rbf_kernel(all_rbf, y_train, gamma=1 / sig)\n",
    "all_y = regression.predict(expanded_rbf)\n",
    "\n",
    "print(\"all_x.shape\", all_rbf.shape)\n",
    "print(\"expanded_x.shape\", expanded_rbf.shape)\n",
    "print(\"all_y.shape\", all_y.shape)\n",
    "\n",
    "# Show that the predictions tend to zero far away from inputs\n",
    "plt.figure()\n",
    "plt.plot(all_rbf, all_y)\n",
    "#plt.scatter(x_train, weights)\n",
    "\n",
    "# Zoom in and see how well predictions fit the data\n",
    "zoom_ind = (all_rbf > x_train.min()) & (all_rbf < x_train.max())\n",
    "plt.figure()\n",
    "print(len(zoom_ind))\n",
    "\n",
    "#plt.plot(all_rbf[zoom_ind], all_y[zoom_ind])\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
